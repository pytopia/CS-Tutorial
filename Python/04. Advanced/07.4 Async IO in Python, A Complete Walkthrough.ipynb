{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"../../images/banners/python-advanced.png\" width=\"600\"/>"]}, {"cell_type": "markdown", "source": ["# <img src=\"../../images/logos/python.png\" width=\"23\"/> Async IO in Python: A Complete Walkthrough \n"], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## <img src=\"../../images/logos/toc.png\" width=\"20\"/> Table of Contents \n* [Setting Up Your Environment](#setting_up_your_environment)\n* [The 10,000-Foot View of Async IO](#the_10,000-foot_view_of_async_io)\n    * [Where Does Async IO Fit In?](#where_does_async_io_fit_in?)\n    * [Async IO Explained](#async_io_explained)\n    * [Async IO Is Not Easy](#async_io_is_not_easy)\n* [The `asyncio` Package and `async`/`await`](#the_`asyncio`_package_and_`async`/`await`)\n    * [The `async`/`await` Syntax and Native Coroutines](#the_`async`/`await`_syntax_and_native_coroutines)\n    * [The Rules of Async IO](#the_rules_of_async_io)\n* [Async IO Design Patterns](#async_io_design_patterns)\n    * [Chaining Coroutines](#chaining_coroutines)\n    * [Using a Queue](#using_a_queue)\n* [Async IO\u2019s Roots in Generators](#async_io\u2019s_roots_in_generators)\n    * [Other Features: `async for` and Async Generators + Comprehensions](#other_features:_`async_for`_and_async_generators_+_comprehensions)\n    * [The Event Loop and `asyncio.run()`](#the_event_loop_and_`asyncio.run()`)\n* [A Full Program: Asynchronous Requests](#a_full_program:_asynchronous_requests)\n* [Async IO in Context](#async_io_in_context)\n    * [When and Why Is Async IO the Right Choice?](#when_and_why_is_async_io_the_right_choice?)\n    * [Async IO It Is, but Which One?](#async_io_it_is,_but_which_one?)\n* [Odds and Ends](#odds_and_ends)\n    * [Other Top-Level `asyncio` Functions](#other_top-level_`asyncio`_functions)\n    * [The Precedence of `await`](#the_precedence_of_`await`)\n* [Conclusion](#conclusion)\n* [Resources](#resources)\n    * [Python Version Specifics](#python_version_specifics)\n    * [Articles](#articles)\n    * [Related PEPs](#related_peps)\n    * [Libraries That Work With `async`/`await`](#libraries_that_work_with_`async`/`await`)\n\n---"]}, {"cell_type": "markdown", "source": ["Async IO is a concurrent programming design that has received dedicated support in Python, evolving rapidly from Python 3.4 through 3.7, and [probably beyond](https://twitter.com/1st1/status/1041855365745455104)."], "metadata": {}}, {"cell_type": "markdown", "source": ["You may be thinking with dread, \u201cConcurrency, parallelism, threading, multiprocessing. That\u2019s a lot to grasp already. Where does async IO fit in?\u201d"], "metadata": {}}, {"cell_type": "markdown", "source": ["This tutorial is built to help you answer that question, giving you a firmer grasp of Python\u2019s approach to async IO."], "metadata": {}}, {"cell_type": "markdown", "source": ["**Here\u2019s what you\u2019ll cover:**"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \n**Asynchronous IO (async IO)**: a language-agnostic paradigm (model) that has implementations across a host of programming languages\n\n\n\n- \n**`async`/`await`**: two new [Python keywords](https://realpython.com/python-keywords/) that are used to define coroutines\n\n\n\n- \n**`asyncio`**: the Python package that provides a foundation and API for running and managing coroutines\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["Coroutines (specialized generator functions) are the heart of async IO in Python, and we\u2019ll dive into them later on."], "metadata": {}}, {"cell_type": "markdown", "source": ["Before you get started, you\u2019ll need to make sure you\u2019re set up to use `asyncio` and other libraries found in this tutorial."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"setting_up_your_environment\"></a>\n", "\n", "## Setting Up Your Environment"], "metadata": {}}, {"cell_type": "markdown", "source": ["You\u2019ll need Python 3.7 or above to follow this article in its entirety, as well as the `aiohttp` and `aiofiles` packages:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3.7 -m venv ./py37async\n$ source ./py37async/bin/activate  # Windows: .\\py37async\\Scripts\\activate.bat\n$ pip install --upgrade pip aiohttp aiofiles  # Optional: aiodns\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["For help with installing Python 3.7 and setting up a virtual environment, check out [Python 3 Installation & Setup Guide](https://realpython.com/installing-python/) or [Virtual Environments Primer](https://realpython.com/python-virtual-environments-a-primer/)."], "metadata": {}}, {"cell_type": "markdown", "source": ["With that, let\u2019s jump in."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_10,000-foot_view_of_async_io\"></a>\n", "\n", "## The 10,000-Foot View of Async IO"], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO is a bit lesser known than its tried-and-true cousins, multiprocessing and [threading](https://realpython.com/intro-to-python-threading/). This section will give you a fuller picture of what async IO is and how it fits into its surrounding landscape."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"where_does_async_io_fit_in?\"></a>\n", "\n", "### Where Does Async IO Fit In?"], "metadata": {}}, {"cell_type": "markdown", "source": ["Concurrency and parallelism are expansive subjects that are not easy to wade into. While this article focuses on async IO and its implementation in Python, it\u2019s worth taking a minute to compare async IO to its counterparts in order to have context about how async IO fits into the larger, sometimes dizzying puzzle."], "metadata": {}}, {"cell_type": "markdown", "source": ["**Parallelism** consists of performing multiple operations at the same time. **Multiprocessing** is a means to effect parallelism, and it entails spreading tasks over a computer\u2019s central processing units (CPUs, or cores). Multiprocessing is well-suited for CPU-bound tasks: tightly bound [`for` loops](https://realpython.com/python-for-loop/) and mathematical computations usually fall into this category."], "metadata": {}}, {"cell_type": "markdown", "source": ["**Concurrency** is a slightly broader term than parallelism. It suggests that multiple tasks have the ability to run in an overlapping manner. (There\u2019s a saying that concurrency does not imply parallelism.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["**Threading** is a concurrent execution model whereby multiple [threads](https://en.wikipedia.org/wiki/Thread_(computing)) take turns executing tasks. One process can contain multiple threads. Python has a complicated relationship with threading thanks to its [GIL](https://realpython.com/python-gil/), but that\u2019s beyond the scope of this article."], "metadata": {}}, {"cell_type": "markdown", "source": ["What\u2019s important to know about threading is that it\u2019s better for IO-bound tasks. While a CPU-bound task is characterized by the computer\u2019s cores continually working hard from start to finish, an IO-bound job is dominated by a lot of waiting on input/output to complete."], "metadata": {}}, {"cell_type": "markdown", "source": ["To recap the above, concurrency encompasses both multiprocessing (ideal for CPU-bound tasks) and threading (suited for IO-bound tasks). Multiprocessing is a form of parallelism, with parallelism being a specific type (subset) of concurrency. The Python standard library has offered longstanding [support for both of these](https://docs.python.org/3/library/concurrency.html) through its `multiprocessing`, `threading`, and `concurrent.futures` packages."], "metadata": {}}, {"cell_type": "markdown", "source": ["Now it\u2019s time to bring a new member to the mix. Over the last few years, a separate design has been more comprehensively built into [CPython](https://realpython.com/cpython-source-code-guide/): asynchronous IO, enabled through the standard library\u2019s `asyncio` package and the new `async` and `await` language keywords. To be clear, async IO is not a newly invented concept, and it has existed or is being built into other languages and runtime environments, such as [Go](https://gobyexample.com/goroutines), [C#](https://docs.microsoft.com/en-us/dotnet/csharp/async), or [Scala](https://docs.scala-lang.org/sips/async.html)."], "metadata": {}}, {"cell_type": "markdown", "source": ["The `asyncio` package is billed by the Python documentation as [a library to write concurrent code](https://docs.python.org/3/library/asyncio.html). However, async IO is not threading, nor is it multiprocessing. It is not built on top of either of these."], "metadata": {}}, {"cell_type": "markdown", "source": ["In fact, async IO is a single-threaded, single-process design: it uses **cooperative multitasking**, a term that you\u2019ll flesh out by the end of this tutorial. It has been said in other words that async IO gives a feeling of concurrency despite using a single thread in a single process. Coroutines (a central feature of async IO) can be scheduled concurrently, but they are not inherently concurrent."], "metadata": {}}, {"cell_type": "markdown", "source": ["To reiterate, async IO is a style of concurrent programming, but it is not parallelism. It\u2019s more closely aligned with threading than with multiprocessing but is very much distinct from both of these and is a standalone member in concurrency\u2019s bag of tricks."], "metadata": {}}, {"cell_type": "markdown", "source": ["That leaves one more term. What does it mean for something to be **asynchronous**? This isn\u2019t a rigorous definition, but for our purposes here, I can think of two properties:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- Asynchronous routines are able to \u201cpause\u201d while waiting on their ultimate result and let other routines run in the meantime.\n- [Asynchronous code](https://realpython.com/python-async-features/), through the mechanism above, facilitates concurrent execution. To put it differently, asynchronous code gives the look and feel of concurrency.\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["Here\u2019s a diagram to put it all together. The white terms represent concepts, and the green terms represent ways in which they are implemented or effected:"], "metadata": {}}, {"cell_type": "markdown", "source": ["<img src=\"images/async-io-in-python:-a-complete-walkthrough/Screen_Shot_2018-10-17_at_3.18.44_PM.c02792872031.jpg\" width=\"600px\">"], "metadata": {}}, {"cell_type": "markdown", "source": ["I\u2019ll stop there on the comparisons between concurrent programming models. This tutorial is focused on the subcomponent that is async IO, how to use it, and the [APIs](https://realpython.com/python-api/) that have sprung up around it. For a thorough exploration of threading versus multiprocessing versus async IO, pause here and check out Jim Anderson\u2019s [overview of concurrency in Python](https://realpython.com/python-concurrency/). Jim is way funnier than me and has sat in more meetings than me, to boot."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io_explained\"></a>\n", "\n", "### Async IO Explained"], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO may at first seem counterintuitive and paradoxical. How does something that facilitates concurrent code use a single thread and a single CPU core? I\u2019ve never been very good at conjuring up examples, so I\u2019d like to paraphrase one from Miguel Grinberg\u2019s 2017 PyCon talk, which explains everything quite beautifully:"], "metadata": {}}, {"cell_type": "markdown", "source": ["There is only one Judit Polg\u00e1r, who has only two hands and makes only one move at a time by herself. But playing asynchronously cuts the exhibition time down from 12 hours to one. So, cooperative multitasking is a fancy way of saying that a program\u2019s event loop (more on that later) communicates with multiple tasks to let each take turns running at the optimal time."], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO takes long waiting periods in which functions would otherwise be blocking and allows other functions to run during that downtime. (A function that blocks effectively forbids others from running from the time that it starts until the time that it returns.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io_is_not_easy\"></a>\n", "\n", "### Async IO Is Not Easy"], "metadata": {}}, {"cell_type": "markdown", "source": ["I\u2019ve heard it said, \u201cUse async IO when you can; use threading when you must.\u201d The truth is that building durable multithreaded code can be hard and error-prone. Async IO avoids some of the potential speedbumps that you might otherwise encounter with a threaded design."], "metadata": {}}, {"cell_type": "markdown", "source": ["But that\u2019s not to say that async IO in Python is easy. Be warned: when you venture a bit below the surface level, async programming can be difficult too! Python\u2019s async model is built around concepts such as callbacks, events, transports, protocols, and futures\u2014just the terminology can be intimidating. The fact that its API has been changing continually makes it no easier."], "metadata": {}}, {"cell_type": "markdown", "source": ["Luckily, `asyncio` has matured to a point where most of its features are no longer provisional, while its documentation has received a huge overhaul and some quality resources on the subject are starting to emerge as well."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_`asyncio`_package_and_`async`/`await`\"></a>\n", "\n", "## The `asyncio` Package and `async`/`await`"], "metadata": {}}, {"cell_type": "markdown", "source": ["Now that you have some background on async IO as a design, let\u2019s explore Python\u2019s implementation. Python\u2019s `asyncio` package (introduced in Python 3.4) and its two keywords, `async` and `await`, serve different purposes but come together to help you declare, build, execute, and manage asynchronous code."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_`async`/`await`_syntax_and_native_coroutines\"></a>\n", "\n", "### The `async`/`await` Syntax and Native Coroutines"], "metadata": {}}, {"cell_type": "markdown", "source": ["At the heart of async IO are coroutines. A coroutine is a specialized version of a Python generator function. Let\u2019s start with a baseline definition and then build off of it as you progress here: a coroutine is a function that can suspend its execution before reaching `return`, and it can indirectly pass control to another coroutine for some time."], "metadata": {}}, {"cell_type": "markdown", "source": ["Later, you\u2019ll dive a lot deeper into how exactly the traditional generator is repurposed into a coroutine. For now, the easiest way to pick up how coroutines work is to start making some."], "metadata": {}}, {"cell_type": "markdown", "source": ["Let\u2019s take the immersive approach and write some async IO code. This short program is the `Hello World` of async IO but goes a long way towards illustrating its core functionality:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# countasync.py\n\nimport asyncio\n\nasync def count():\n    print(\"One\")\n    await asyncio.sleep(1)\n    print(\"Two\")\n\nasync def main():\n    await asyncio.gather(count(), count(), count())\n\nif __name__ == \"__main__\":\n    import time\n    s = time.perf_counter()\n    asyncio.run(main())\n    elapsed = time.perf_counter() - s\n    print(f\"{__file__} executed in {elapsed:0.2f} seconds.\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["When you execute this file, take note of what looks different than if you were to define the functions with just `def` and `time.sleep()`:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3 countasync.py\nOne\nOne\nOne\nTwo\nTwo\nTwo\ncountasync.py executed in 1.01 seconds.\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["The order of this output is the heart of async IO. Talking to each of the calls to `count()` is a single event loop, or coordinator. When each task reaches `await asyncio.sleep(1)`, the function yells up to the event loop and gives control back to it, saying, \u201cI\u2019m going to be sleeping for 1 second. Go ahead and let something else meaningful be done in the meantime.\u201d"], "metadata": {}}, {"cell_type": "markdown", "source": ["Contrast this to the synchronous version:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# countsync.py\n\nimport time\n\ndef count():\n    print(\"One\")\n    time.sleep(1)\n    print(\"Two\")\n\ndef main():\n    for _ in range(3):\n        count()\n\nif __name__ == \"__main__\":\n    s = time.perf_counter()\n    main()\n    elapsed = time.perf_counter() - s\n    print(f\"{__file__} executed in {elapsed:0.2f} seconds.\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["When executed, there is a slight but critical change in order and execution time:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3 countsync.py\nOne\nTwo\nOne\nTwo\nOne\nTwo\ncountsync.py executed in 3.01 seconds.\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["While using `time.sleep()` and `asyncio.sleep()` may seem banal, they are used as stand-ins for any time-intensive processes that involve wait time. (The most mundane thing you can wait on is a `sleep()` call that does basically nothing.) That is, `time.sleep()` can represent any time-consuming blocking function call, while `asyncio.sleep()` is used to stand in for a non-blocking call (but one that also takes some time to complete)."], "metadata": {}}, {"cell_type": "markdown", "source": ["As you\u2019ll see in the next section, the benefit of awaiting something, including `asyncio.sleep()`, is that the surrounding function can temporarily cede control to another function that\u2019s more readily able to do something immediately. In contrast, `time.sleep()` or any other blocking call is incompatible with asynchronous Python code, because it will stop everything in its tracks for the duration of the sleep time."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_rules_of_async_io\"></a>\n", "\n", "### The Rules of Async IO"], "metadata": {}}, {"cell_type": "markdown", "source": ["At this point, a more formal definition of `async`, `await`, and the coroutine functions that they create are in order. This section is a little dense, but getting a hold of `async`/`await` is instrumental, so come back to this if you need to:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nThe syntax `async def` introduces either a **native coroutine** or an **asynchronous generator**. The expressions `async with` and `async for` are also valid, and you\u2019ll see them later on.\n\n\n\n- \nThe keyword `await` passes function control back to the event loop. (It suspends the execution of the surrounding coroutine.) If Python encounters an `await f()` expression in the scope of `g()`, this is how `await` tells the event loop, \u201cSuspend execution of `g()` until whatever I\u2019m waiting on\u2014the result of `f()`\u2014is returned. In the meantime, go let something else run.\u201d\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["In code, that second bullet point looks roughly like this:"], "metadata": {}}, {"cell_type": "code", "source": ["async def g():\n    # Pause here and come back to g() when f() is ready\n    r = await f()\n    return r"], "metadata": {}}, {"cell_type": "markdown", "source": ["There\u2019s also a strict set of rules around when and how you can and cannot use `async`/`await`. These can be handy whether you are still picking up the syntax or already have exposure to using `async`/`await`:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nA function that you introduce with `async def` is a coroutine. It may use `await`, `return`, or `yield`, but all of these are optional. Declaring `async def noop(): pass` is valid:\n\n\n* Using `await` and/or `return` creates a coroutine function. To call a coroutine function, you must `await` it to get its results.\n* It is less common (and only recently legal in Python) to use `yield` in an `async def` block. This creates an [asynchronous generator](https://www.python.org/dev/peps/pep-0525/), which you iterate over with `async for`. Forget about async generators for the time being and focus on getting down the syntax for coroutine functions, which use `await` and/or `return`.\n* Anything defined with `async def` may not use `yield from`, which will raise a [`SyntaxError`](https://realpython.com/invalid-syntax-python/).\n\n\n\n- \nJust like it\u2019s a `SyntaxError` to use `yield` outside of a `def` function, it is a `SyntaxError` to use `await` outside of an `async def` coroutine. You can only use `await` in the body of coroutines.\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["Here are some terse examples meant to summarize the above few rules:"], "metadata": {}}, {"cell_type": "code", "source": ["async def f(x):\n    y = await z(x)  # OK - `await` and `return` allowed in coroutines\n    return y\n\nasync def g(x):\n    yield x  # OK - this is an async generator\n\nasync def m(x):\n    yield from gen(x)  # No - SyntaxError\n\ndef m(x):\n    y = await z(x)  # Still no - SyntaxError (no `async def` here)\n    return y"], "metadata": {}}, {"cell_type": "markdown", "source": ["Finally, when you use `await f()`, it\u2019s required that `f()` be an object that is [awaitable](https://docs.python.org/3/reference/datamodel.html#awaitable-objects). Well, that\u2019s not very helpful, is it? For now, just know that an awaitable object is either (1) another coroutine or (2) an object defining an `.__await__()` dunder method that returns an iterator. If you\u2019re writing a program, for the large majority of purposes, you should only need to worry about case #1."], "metadata": {}}, {"cell_type": "markdown", "source": ["That brings us to one more technical distinction that you may see pop up: an older way of marking a function as a coroutine is to decorate a normal `def` function with `@asyncio.coroutine`. The result is a **generator-based coroutine**. This construction has been outdated since the `async`/`await` syntax was put in place in Python 3.5."], "metadata": {}}, {"cell_type": "markdown", "source": ["These two coroutines are essentially equivalent (both are awaitable), but the first is **generator-based**, while the second is a **native coroutine**:"], "metadata": {}}, {"cell_type": "code", "source": ["import asyncio\n\n@asyncio.coroutine\ndef py34_coro():\n    \"\"\"Generator-based coroutine, older syntax\"\"\"\n    yield from stuff()\n\nasync def py35_coro():\n    \"\"\"Native coroutine, modern syntax\"\"\"\n    await stuff()"], "metadata": {}}, {"cell_type": "markdown", "source": ["If you\u2019re writing any code yourself, prefer native coroutines for the sake of being explicit rather than implicit. Generator-based coroutines will be [removed](https://docs.python.org/3/library/asyncio-task.html#generator-based-coroutines) in Python 3.10."], "metadata": {}}, {"cell_type": "markdown", "source": ["Towards the latter half of this tutorial, we\u2019ll touch on generator-based coroutines for explanation\u2019s sake only. The reason that `async`/`await` were introduced is to make coroutines a standalone feature of Python that can be easily differentiated from a normal generator function, thus reducing ambiguity."], "metadata": {}}, {"cell_type": "markdown", "source": ["Don\u2019t get bogged down in generator-based coroutines, which have been [deliberately outdated](https://www.python.org/dev/peps/pep-0492/#rationale-and-goals) by `async`/`await`. They have their own small set of rules (for instance, `await` cannot be used in a generator-based coroutine) that are largely irrelevant if you stick to the `async`/`await` syntax."], "metadata": {}}, {"cell_type": "markdown", "source": ["Without further ado, let\u2019s take on a few more involved examples."], "metadata": {}}, {"cell_type": "markdown", "source": ["Here\u2019s one example of how async IO cuts down on wait time: given a coroutine `makerandom()` that keeps producing random integers in the range [0, 10], until one of them exceeds a threshold, you want to let multiple calls of this coroutine not need to wait for each other to complete in succession. You can largely follow the patterns from the two scripts above, with slight changes:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# rand.py\n\nimport asyncio\nimport random\n\n# ANSI colors\nc = (\n    \"\\033[0m\",   # End of color\n    \"\\033[36m\",  # Cyan\n    \"\\033[91m\",  # Red\n    \"\\033[35m\",  # Magenta\n)\n\nasync def makerandom(idx: int, threshold: int = 6) -> int:\n    print(c[idx + 1] + f\"Initiated makerandom({idx}).\")\n    i = random.randint(0, 10)\n    while i <= threshold:\n        print(c[idx + 1] + f\"makerandom({idx}) == {i} too low; retrying.\")\n        await asyncio.sleep(idx + 1)\n        i = random.randint(0, 10)\n    print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n    return i\n\nasync def main():\n    res = await asyncio.gather(*(makerandom(i, 10 - i - 1) for i in range(3)))\n    return res\n\nif __name__ == \"__main__\":\n    random.seed(444)\n    r1, r2, r3 = asyncio.run(main())\n    print()\n    print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["The colorized output says a lot more than I can and gives you a sense for how this script is carried out:"], "metadata": {}}, {"cell_type": "markdown", "source": ["<img src=\"images/async-io-in-python:-a-complete-walkthrough/asyncio-rand.dffdd83b4256.gif\" width=\"600px\">"], "metadata": {}}, {"cell_type": "markdown", "source": ["This program uses one main coroutine, `makerandom()`, and runs it concurrently across 3 different inputs. Most programs will contain small, modular coroutines and one wrapper function that serves to chain each of the smaller coroutines together. [`main()`](https://realpython.com/python-main-function/) is then used to gather tasks (futures) by mapping the central coroutine across some iterable or pool."], "metadata": {}}, {"cell_type": "markdown", "source": ["In this miniature example, the pool is `range(3)`. In a fuller example presented later, it is a set of URLs that need to be requested, parsed, and processed concurrently, and `main()` encapsulates that entire routine for each URL."], "metadata": {}}, {"cell_type": "markdown", "source": ["While \u201cmaking random integers\u201d (which is CPU-bound more than anything) is maybe not the greatest choice as a candidate for `asyncio`, it\u2019s the presence of `asyncio.sleep()` in the example that is designed to mimic an IO-bound process where there is uncertain wait time involved. For example, the `asyncio.sleep()` call might represent sending and receiving not-so-random integers between two clients in a message application."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io_design_patterns\"></a>\n", "\n", "## Async IO Design Patterns"], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO comes with its own set of possible script designs, which you\u2019ll get introduced to in this section."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"chaining_coroutines\"></a>\n", "\n", "### Chaining Coroutines"], "metadata": {}}, {"cell_type": "markdown", "source": ["A key feature of coroutines is that they can be chained together. (Remember, a coroutine object is awaitable, so another coroutine can `await` it.) This allows you to break programs into smaller, manageable, recyclable coroutines:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# chained.py\n\nimport asyncio\nimport random\nimport time\n\nasync def part1(n: int) -> str:\n    i = random.randint(0, 10)\n    print(f\"part1({n}) sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n    result = f\"result{n}-1\"\n    print(f\"Returning part1({n}) == {result}.\")\n    return result\n\nasync def part2(n: int, arg: str) -> str:\n    i = random.randint(0, 10)\n    print(f\"part2{n, arg} sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n    result = f\"result{n}-2 derived from {arg}\"\n    print(f\"Returning part2{n, arg} == {result}.\")\n    return result\n\nasync def chain(n: int) -> None:\n    start = time.perf_counter()\n    p1 = await part1(n)\n    p2 = await part2(n, p1)\n    end = time.perf_counter() - start\n    print(f\"-->Chained result{n} => {p2} (took {end:0.2f} seconds).\")\n\nasync def main(*args):\n    await asyncio.gather(*(chain(n) for n in args))\n\nif __name__ == \"__main__\":\n    import sys\n    random.seed(444)\n    args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:])\n    start = time.perf_counter()\n    asyncio.run(main(*args))\n    end = time.perf_counter() - start\n    print(f\"Program finished in {end:0.2f} seconds.\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["Pay careful attention to the output, where `part1()` sleeps for a variable amount of time, and `part2()` begins working with the results as they become available:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3 chained.py 9 6 3\npart1(9) sleeping for 4 seconds.\npart1(6) sleeping for 4 seconds.\npart1(3) sleeping for 0 seconds.\nReturning part1(3) == result3-1.\npart2(3, 'result3-1') sleeping for 4 seconds.\nReturning part1(9) == result9-1.\npart2(9, 'result9-1') sleeping for 7 seconds.\nReturning part1(6) == result6-1.\npart2(6, 'result6-1') sleeping for 4 seconds.\nReturning part2(3, 'result3-1') == result3-2 derived from result3-1.\n-->Chained result3 => result3-2 derived from result3-1 (took 4.00 seconds).\nReturning part2(6, 'result6-1') == result6-2 derived from result6-1.\n-->Chained result6 => result6-2 derived from result6-1 (took 8.01 seconds).\nReturning part2(9, 'result9-1') == result9-2 derived from result9-1.\n-->Chained result9 => result9-2 derived from result9-1 (took 11.01 seconds).\nProgram finished in 11.01 seconds.\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["In this setup, the runtime of `main()` will be equal to the maximum runtime of the tasks that it gathers together and schedules."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"using_a_queue\"></a>\n", "\n", "### Using a Queue"], "metadata": {}}, {"cell_type": "markdown", "source": ["The `asyncio` package provides [queue classes](https://docs.python.org/3/library/asyncio-queue.html) that are designed to be similar to classes of the [`queue`](https://docs.python.org/3/library/queue.html#module-queue) module. In our examples so far, we haven\u2019t really had a need for a queue structure. In `chained.py`, each task (future) is composed of a set of coroutines that explicitly await each other and pass through a single input per chain."], "metadata": {}}, {"cell_type": "markdown", "source": ["There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal."], "metadata": {}}, {"cell_type": "markdown", "source": ["In this design, there is no chaining of any individual consumer to a producer. The consumers don\u2019t know the number of producers, or even the cumulative number of items that will be added to the queue, in advance."], "metadata": {}}, {"cell_type": "markdown", "source": ["It takes an individual producer or consumer a variable amount of time to put and extract items from the queue, respectively. The queue serves as a throughput that can communicate with the producers and consumers without them talking to each other directly."], "metadata": {}}, {"cell_type": "markdown", "source": ["The synchronous version of this program would look pretty dismal: a group of blocking producers serially add items to the queue, one producer at a time. Only after all producers are done can the queue be processed, by one consumer at a time processing item-by-item. There is a ton of latency in this design. Items may sit idly in the queue rather than be picked up and processed immediately."], "metadata": {}}, {"cell_type": "markdown", "source": ["An asynchronous version, `asyncq.py`, is below. The challenging part of this workflow is that there needs to be a signal to the consumers that production is done. Otherwise, `await q.get()` will hang indefinitely, because the queue will have been fully processed, but consumers won\u2019t have any idea that production is complete."], "metadata": {}}, {"cell_type": "markdown", "source": ["(Big thanks for some help from a StackOverflow [user](https://stackoverflow.com/a/52615705/7954504) for helping to straighten out `main()`: the key is to `await q.join()`, which blocks until all items in the queue have been received and processed, and then to cancel the consumer tasks, which would otherwise hang up and wait endlessly for additional queue items to appear.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["Here is the full script:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# asyncq.py\n\nimport asyncio\nimport itertools as it\nimport os\nimport random\nimport time\n\nasync def makeitem(size: int = 5) -> str:\n    return os.urandom(size).hex()\n\nasync def randsleep(caller=None) -> None:\n    i = random.randint(0, 10)\n    if caller:\n        print(f\"{caller} sleeping for {i} seconds.\")\n    await asyncio.sleep(i)\n\nasync def produce(name: int, q: asyncio.Queue) -> None:\n    n = random.randint(0, 10)\n    for _ in it.repeat(None, n):  # Synchronous loop for each single producer\n        await randsleep(caller=f\"Producer {name}\")\n        i = await makeitem()\n        t = time.perf_counter()\n        await q.put((i, t))\n        print(f\"Producer {name} added <{i}> to queue.\")\n\nasync def consume(name: int, q: asyncio.Queue) -> None:\n    while True:\n        await randsleep(caller=f\"Consumer {name}\")\n        i, t = await q.get()\n        now = time.perf_counter()\n        print(f\"Consumer {name} got element <{i}>\"\n              f\" in {now-t:0.5f} seconds.\")\n        q.task_done()\n\nasync def main(nprod: int, ncon: int):\n    q = asyncio.Queue()\n    producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)]\n    consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)]\n    await asyncio.gather(*producers)\n    await q.join()  # Implicitly awaits consumers, too\n    for c in consumers:\n        c.cancel()\n\nif __name__ == \"__main__\":\n    import argparse\n    random.seed(444)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--nprod\", type=int, default=5)\n    parser.add_argument(\"-c\", \"--ncon\", type=int, default=10)\n    ns = parser.parse_args()\n    start = time.perf_counter()\n    asyncio.run(main(**ns.__dict__))\n    elapsed = time.perf_counter() - start\n    print(f\"Program completed in {elapsed:0.5f} seconds.\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["The first few coroutines are helper functions that return a random string, a fractional-second performance counter, and a random integer. A producer puts anywhere from 1 to 5 items into the queue. Each item is a tuple of `(i, t)` where `i` is a random string and `t` is the time at which the producer attempts to put the tuple into the queue."], "metadata": {}}, {"cell_type": "markdown", "source": ["When a consumer pulls an item out, it simply calculates the elapsed time that the item sat in the queue using the timestamp that the item was put in with."], "metadata": {}}, {"cell_type": "markdown", "source": ["Keep in mind that `asyncio.sleep()` is used to mimic some other, more complex coroutine that would eat up time and block all other execution if it were a regular blocking function."], "metadata": {}}, {"cell_type": "markdown", "source": ["Here is a test run with two producers and five consumers:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3 asyncq.py -p 2 -c 5\nProducer 0 sleeping for 3 seconds.\nProducer 1 sleeping for 3 seconds.\nConsumer 0 sleeping for 4 seconds.\nConsumer 1 sleeping for 3 seconds.\nConsumer 2 sleeping for 3 seconds.\nConsumer 3 sleeping for 5 seconds.\nConsumer 4 sleeping for 4 seconds.\nProducer 0 added <377b1e8f82> to queue.\nProducer 0 sleeping for 5 seconds.\nProducer 1 added <413b8802f8> to queue.\nConsumer 1 got element <377b1e8f82> in 0.00013 seconds.\nConsumer 1 sleeping for 3 seconds.\nConsumer 2 got element <413b8802f8> in 0.00009 seconds.\nConsumer 2 sleeping for 4 seconds.\nProducer 0 added <06c055b3ab> to queue.\nProducer 0 sleeping for 1 seconds.\nConsumer 0 got element <06c055b3ab> in 0.00021 seconds.\nConsumer 0 sleeping for 4 seconds.\nProducer 0 added <17a8613276> to queue.\nConsumer 4 got element <17a8613276> in 0.00022 seconds.\nConsumer 4 sleeping for 5 seconds.\nProgram completed in 9.00954 seconds.\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["In this case, the items process in fractions of a second. A delay can be due to two reasons:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- Standard, largely unavoidable overhead\n- Situations where all consumers are sleeping when an item appears in the queue\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["With regards to the second reason, luckily, it is perfectly normal to scale to hundreds or thousands of consumers. You should have no problem with `python3 asyncq.py -p 5 -c 100`. The point here is that, theoretically, you could have different users on different systems controlling the management of producers and consumers, with the queue serving as the central throughput."], "metadata": {}}, {"cell_type": "markdown", "source": ["So far, you\u2019ve been thrown right into the fire and seen three related examples of `asyncio` calling coroutines defined with `async` and `await`. If you\u2019re not completely following or just want to get deeper into the mechanics of how modern coroutines came to be in Python, you\u2019ll start from square one with the next section."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io\u2019s_roots_in_generators\"></a>\n", "\n", "## Async IO\u2019s Roots in Generators"], "metadata": {}}, {"cell_type": "markdown", "source": ["Earlier, you saw an example of the old-style generator-based coroutines, which have been outdated by more explicit native coroutines. The example is worth re-showing with a small tweak:"], "metadata": {}}, {"cell_type": "code", "source": ["import asyncio\n\n@asyncio.coroutine\ndef py34_coro():\n    \"\"\"Generator-based coroutine\"\"\"\n    # No need to build these yourself, but be aware of what they are\n    s = yield from stuff()\n    return s\n\nasync def py35_coro():\n    \"\"\"Native coroutine, modern syntax\"\"\"\n    s = await stuff()\n    return s\n\nasync def stuff():\n    return 0x10, 0x20, 0x30"], "metadata": {}}, {"cell_type": "markdown", "source": ["As an experiment, what happens if you call `py34_coro()` or `py35_coro()` on its own, without `await`, or without any calls to `asyncio.run()` or other `asyncio` \u201cporcelain\u201d functions? Calling a coroutine in isolation returns a coroutine object:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> py35_coro()\n<coroutine object py35_coro at 0x10126dcc8>"], "metadata": {}}, {"cell_type": "markdown", "source": ["This isn\u2019t very interesting on its surface. The result of calling a coroutine on its own is an awaitable **coroutine object**."], "metadata": {}}, {"cell_type": "markdown", "source": ["Time for a quiz: what other feature of Python looks like this? (What feature of Python doesn\u2019t actually \u201cdo much\u201d when it\u2019s called on its own?)"], "metadata": {}}, {"cell_type": "markdown", "source": ["Hopefully you\u2019re thinking of **generators** as an answer to this question, because coroutines are enhanced generators under the hood. The behavior is similar in this regard:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> def gen():\n...     yield 0x10, 0x20, 0x30\n...\n>>> g = gen()\n>>> g  # Nothing much happens - need to iterate with `.__next__()`\n<generator object gen at 0x1012705e8>\n>>> next(g)\n(16, 32, 48)"], "metadata": {}}, {"cell_type": "markdown", "source": ["Generator functions are, as it so happens, the foundation of async IO (regardless of whether you declare coroutines with `async def` rather than the older `@asyncio.coroutine` wrapper). Technically, `await` is more closely analogous to `yield from` than it is to `yield`. (But remember that `yield from x()` is just syntactic sugar to replace `for i in x(): yield i`.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["One critical feature of generators as it pertains to async IO is that they can effectively be stopped and restarted at will. For example, you can `break` out of iterating over a generator object and then resume iteration on the remaining values later. When a [generator function reaches `yield`](https://realpython.com/introduction-to-python-generators/), it yields that value, but then it sits idle until it is told to yield its subsequent value."], "metadata": {}}, {"cell_type": "markdown", "source": ["This can be fleshed out through an example:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> from itertools import cycle\n>>> def endless():\n...     \"\"\"Yields 9, 8, 7, 6, 9, 8, 7, 6, ... forever\"\"\"\n...     yield from cycle((9, 8, 7, 6))\n\n>>> e = endless()\n>>> total = 0\n>>> for i in e:\n...     if total < 30:\n...         print(i, end=\" \")\n...         total += i\n...     else:\n...         print()\n...         # Pause execution. We can resume later.\n...         break\n9 8 7 6 9 8 7 6 9 8 7 6 9 8\n\n>>> # Resume\n>>> next(e), next(e), next(e)\n(6, 9, 8)"], "metadata": {}}, {"cell_type": "markdown", "source": ["The `await` keyword behaves similarly, marking a break point at which the coroutine suspends itself and lets other coroutines work. \u201cSuspended,\u201d in this case, means a coroutine that has temporarily ceded control but not totally exited or finished. Keep in mind that `yield`, and by extension `yield from` and `await`, mark a break point in a generator\u2019s execution."], "metadata": {}}, {"cell_type": "markdown", "source": ["This is the fundamental difference between functions and generators. A function is all-or-nothing. Once it starts, it won\u2019t stop until it hits a `return`, then pushes that value to the caller (the function that calls it). A generator, on the other hand, pauses each time it hits a `yield` and goes no further. Not only can it push this value to calling stack, but it can keep a hold of its local variables when you resume it by calling `next()` on it."], "metadata": {}}, {"cell_type": "markdown", "source": ["There\u2019s a second and lesser-known feature of generators that also matters. You can send a value into a generator as well through its `.send()` method. This allows generators (and coroutines) to call (`await`) each other without blocking. I won\u2019t get any further into the nuts and bolts of this feature, because it matters mainly for the implementation of coroutines behind the scenes, but you shouldn\u2019t ever really need to use it directly yourself."], "metadata": {}}, {"cell_type": "markdown", "source": ["If you\u2019re interested in exploring more, you can start at [PEP 342](https://www.python.org/dev/peps/pep-0342/), where coroutines were formally introduced. Brett Cannon\u2019s [How the Heck Does Async-Await Work in Python](https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/) is also a good read, as is the [PYMOTW writeup on `asyncio`](https://pymotw.com/3/asyncio/coroutines.html). Lastly, there\u2019s David Beazley\u2019s [Curious Course on Coroutines and Concurrency](http://www.dabeaz.com/coroutines/), which dives deep into the mechanism by which coroutines run."], "metadata": {}}, {"cell_type": "markdown", "source": ["Let\u2019s try to condense all of the above articles into a few sentences: there is a particularly unconventional mechanism by which these coroutines actually get run. Their result is an attribute of the exception object that gets thrown when their `.send()` method is called. There\u2019s some more wonky detail to all of this, but it probably won\u2019t help you use this part of the language in practice, so let\u2019s move on for now."], "metadata": {}}, {"cell_type": "markdown", "source": ["To tie things together, here are some key points on the topic of coroutines as generators:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nCoroutines are [repurposed generators](https://www.python.org/dev/peps/pep-0492/#differences-from-generators) that take advantage of the peculiarities of generator methods.\n\n\n\n- \nOld generator-based coroutines use `yield from` to wait for a coroutine result. Modern Python syntax in native coroutines simply replaces `yield from` with `await` as the means of waiting on a coroutine result. The `await` is analogous to `yield from`, and it often helps to think of it as such.\n\n\n\n- \nThe use of `await` is a signal that marks a break point. It lets a coroutine temporarily suspend execution and permits the program to come back to it later.\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"other_features:_`async_for`_and_async_generators_+_comprehensions\"></a>\n", "\n", "### Other Features: `async for` and Async Generators + Comprehensions"], "metadata": {}}, {"cell_type": "markdown", "source": ["Along with plain `async`/`await`, Python also enables `async for` to iterate over an **asynchronous iterator**. The purpose of an asynchronous iterator is for it to be able to call asynchronous code at each stage when it is iterated over."], "metadata": {}}, {"cell_type": "markdown", "source": ["A natural extension of this concept is an **asynchronous generator**. Recall that you can use `await`, `return`, or `yield` in a native coroutine. Using `yield` within a coroutine became possible in Python 3.6 (via PEP 525), which introduced asynchronous generators with the purpose of allowing `await` and `yield` to be used in the same coroutine function body:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> async def mygen(u: int = 10):\n...     \"\"\"Yield powers of 2.\"\"\"\n...     i = 0\n...     while i < u:\n...         yield 2 ** i\n...         i += 1\n...         await asyncio.sleep(0.1)"], "metadata": {}}, {"cell_type": "markdown", "source": ["Last but not least, Python enables **asynchronous comprehension** with `async for`. Like its synchronous cousin, this is largely syntactic sugar:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> async def main():\n...     # This does *not* introduce concurrent execution\n...     # It is meant to show syntax only\n...     g = [i async for i in mygen()]\n...     f = [j async for j in mygen() if not (j // 3 % 5)]\n...     return g, f\n...\n>>> g, f = asyncio.run(main())\n>>> g\n[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n>>> f\n[1, 2, 16, 32, 256, 512]"], "metadata": {}}, {"cell_type": "markdown", "source": ["This is a crucial distinction: **neither asynchronous generators nor comprehensions make the iteration concurrent**. All that they do is provide the look-and-feel of their synchronous counterparts, but with the ability for the loop in question to give up control to the event loop for some other coroutine to run."], "metadata": {}}, {"cell_type": "markdown", "source": ["In other words, asynchronous iterators and asynchronous generators are not designed to concurrently map some function over a sequence or iterator. They\u2019re merely designed to let the enclosing coroutine allow other tasks to take their turn. The `async for` and `async with` statements are only needed to the extent that using plain `for` or `with` would \u201cbreak\u201d the nature of `await` in the coroutine. This distinction between asynchronicity and concurrency is a key one to grasp."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_event_loop_and_`asyncio.run()`\"></a>\n", "\n", "### The Event Loop and `asyncio.run()`"], "metadata": {}}, {"cell_type": "markdown", "source": ["You can think of an event loop as something like a `while True` loop that monitors coroutines, taking feedback on what\u2019s idle, and looking around for things that can be executed in the meantime. It is able to wake up an idle coroutine when whatever that coroutine is waiting on becomes available."], "metadata": {}}, {"cell_type": "markdown", "source": ["Thus far, the entire management of the event loop has been implicitly handled by one function call:"], "metadata": {}}, {"cell_type": "code", "source": ["asyncio.run(main())  # Python 3.7+"], "metadata": {}}, {"cell_type": "markdown", "source": ["[`asyncio.run()`](https://github.com/python/cpython/blob/d4c76d960b8b286b75c933780416ace9cda682fd/Lib/asyncio/runners.py#L8), introduced in Python 3.7, is responsible for getting the event loop, running tasks until they are marked as complete, and then closing the event loop."], "metadata": {}}, {"cell_type": "markdown", "source": ["There\u2019s a more long-winded way of managing the `asyncio` event loop, with `get_event_loop()`. The typical pattern looks like this:"], "metadata": {}}, {"cell_type": "code", "source": ["loop = asyncio.get_event_loop()\ntry:\n    loop.run_until_complete(main())\nfinally:\n    loop.close()"], "metadata": {}}, {"cell_type": "markdown", "source": ["You\u2019ll probably see `loop.get_event_loop()` floating around in older examples, but unless you have a specific need to fine-tune control over the event loop management, `asyncio.run()` should be sufficient for most programs."], "metadata": {}}, {"cell_type": "markdown", "source": ["If you do need to interact with the event loop within a Python program, `loop` is a good-old-fashioned Python object that supports introspection with `loop.is_running()` and `loop.is_closed()`. You can manipulate it if you need to get more fine-tuned control, such as in [scheduling a callback](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio-example-lowlevel-helloworld) by passing the loop as an argument."], "metadata": {}}, {"cell_type": "markdown", "source": ["What is more crucial is understanding a bit beneath the surface about the mechanics of the event loop. Here are a few points worth stressing about the event loop."], "metadata": {}}, {"cell_type": "markdown", "source": ["**#1:** Coroutines don\u2019t do much on their own until they are tied to the event loop."], "metadata": {}}, {"cell_type": "markdown", "source": ["You saw this point before in the explanation on generators, but it\u2019s worth restating. If you have a main coroutine that awaits others, simply calling it in isolation has little effect:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> import asyncio\n\n>>> async def main():\n...     print(\"Hello ...\")\n...     await asyncio.sleep(1)\n...     print(\"World!\")\n\n>>> routine = main()\n>>> routine\n<coroutine object main at 0x1027a6150>"], "metadata": {}}, {"cell_type": "markdown", "source": ["Remember to use `asyncio.run()` to actually force execution by scheduling the `main()` coroutine (future object) for execution on the event loop:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> asyncio.run(routine)\nHello ...\nWorld!"], "metadata": {}}, {"cell_type": "markdown", "source": ["(Other coroutines can be executed with `await`. It is typical to wrap just `main()` in `asyncio.run()`, and chained coroutines with `await` will be called from there.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["**#2:** By default, an async IO event loop runs in a single thread and on a single CPU core. Usually, running one single-threaded event loop in one CPU core is more than sufficient. It is also possible to run event loops across multiple cores. Check out this [talk by John Reese](https://youtu.be/0kXaLh8Fz3k?t=10m30s) for more, and be warned that your laptop may spontaneously combust."], "metadata": {}}, {"cell_type": "markdown", "source": ["**#3.** Event loops are pluggable. That is, you could, if you really wanted, write your own event loop implementation and have it run tasks just the same. This is wonderfully demonstrated in the [`uvloop`](https://github.com/MagicStack/uvloop) package, which is an implementation of the event loop in Cython."], "metadata": {}}, {"cell_type": "markdown", "source": ["That is what is meant by the term \u201cpluggable event loop\u201d: you can use any working implementation of an event loop, unrelated to the structure of the coroutines themselves. The `asyncio` package itself ships with [two different event loop implementations](https://docs.python.org/3/library/asyncio-eventloop.html#event-loop-implementations), with the default being based on the [`selectors`](https://docs.python.org/3/library/selectors.html#module-selectors) module. (The second implementation is built for Windows only.)"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"a_full_program:_asynchronous_requests\"></a>\n", "\n", "## A Full Program: Asynchronous Requests"], "metadata": {}}, {"cell_type": "markdown", "source": ["You\u2019ve made it this far, and now it\u2019s time for the fun and painless part. In this section, you\u2019ll build a web-scraping URL collector, `areq.py`, using `aiohttp`, a blazingly fast async HTTP client/server framework. (We just need the client part.) Such a tool could be used to map connections between a cluster of sites, with the links forming a [directed graph](https://en.wikipedia.org/wiki/Directed_graph)."], "metadata": {}}, {"cell_type": "markdown", "source": ["The high-level program structure will look like this:"], "metadata": {}}, {"cell_type": "markdown", "source": ["1. \nRead a sequence of URLs from a local file, `urls.txt`.\n\n\n\n2. \nSend GET requests for the URLs and decode the resulting content. If this fails, stop there for a URL.\n\n\n\n3. \nSearch for the URLs within `href` tags in the HTML of the responses.\n\n\n\n4. \nWrite the results to `foundurls.txt`.\n\n\n\n5. \nDo all of the above as asynchronously and concurrently as possible. (Use `aiohttp` for the requests, and `aiofiles` for the file-appends. These are two primary examples of IO that are well-suited for the async IO model.)\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["Here are the contents of `urls.txt`. It\u2019s not huge, and contains mostly highly trafficked sites:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ cat urls.txt\nhttps://regex101.com/\nhttps://docs.python.org/3/this-url-will-404.html\nhttps://www.nytimes.com/guides/\nhttps://www.mediamatters.org/\nhttps://1.1.1.1/\nhttps://www.politico.com/tipsheets/morning-money\nhttps://www.bloomberg.com/markets/economics\nhttps://www.ietf.org/rfc/rfc2616.txt\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["The second URL in the list should return a 404 response, which you\u2019ll need to handle gracefully. If you\u2019re running an expanded version of this program, you\u2019ll probably need to deal with much hairier problems than this, such a server disconnections and endless redirects."], "metadata": {}}, {"cell_type": "markdown", "source": ["The requests themselves should be made using a single session, to take advantage of reusage of the session\u2019s internal connection pool."], "metadata": {}}, {"cell_type": "markdown", "source": ["Let\u2019s take a look at the full program. We\u2019ll walk through things step-by-step after:"], "metadata": {}}, {"cell_type": "code", "source": ["#!/usr/bin/env python3\n# areq.py\n\n\"\"\"Asynchronously get links embedded in multiple pages' HMTL.\"\"\"\n\nimport asyncio\nimport logging\nimport re\nimport sys\nfrom typing import IO\nimport urllib.error\nimport urllib.parse\n\nimport aiofiles\nimport aiohttp\nfrom aiohttp import ClientSession\n\nlogging.basicConfig(\n    format=\"%(asctime)s %(levelname)s:%(name)s: %(message)s\",\n    level=logging.DEBUG,\n    datefmt=\"%H:%M:%S\",\n    stream=sys.stderr,\n)\nlogger = logging.getLogger(\"areq\")\nlogging.getLogger(\"chardet.charsetprober\").disabled = True\n\nHREF_RE = re.compile(r'href=\"(.*?)\"')\n\nasync def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n    \"\"\"GET request wrapper to fetch page HTML.\n\n    kwargs are passed to `session.request()`.\n    \"\"\"\n\n    resp = await session.request(method=\"GET\", url=url, **kwargs)\n    resp.raise_for_status()\n    logger.info(\"Got response [%s] for URL: %s\", resp.status, url)\n    html = await resp.text()\n    return html\n\nasync def parse(url: str, session: ClientSession, **kwargs) -> set:\n    \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n    found = set()\n    try:\n        html = await fetch_html(url=url, session=session, **kwargs)\n    except (\n        aiohttp.ClientError,\n        aiohttp.http_exceptions.HttpProcessingError,\n    ) as e:\n        logger.error(\n            \"aiohttp exception for %s [%s]: %s\",\n            url,\n            getattr(e, \"status\", None),\n            getattr(e, \"message\", None),\n        )\n        return found\n    except Exception as e:\n        logger.exception(\n            \"Non-aiohttp exception occured:  %s\", getattr(e, \"__dict__\", {})\n        )\n        return found\n    else:\n        for link in HREF_RE.findall(html):\n            try:\n                abslink = urllib.parse.urljoin(url, link)\n            except (urllib.error.URLError, ValueError):\n                logger.exception(\"Error parsing URL: %s\", link)\n                pass\n            else:\n                found.add(abslink)\n        logger.info(\"Found %d links for %s\", len(found), url)\n        return found\n\nasync def write_one(file: IO, url: str, **kwargs) -> None:\n    \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n    res = await parse(url=url, **kwargs)\n    if not res:\n        return None\n    async with aiofiles.open(file, \"a\") as f:\n        for p in res:\n            await f.write(f\"{url}\\t{p}\\n\")\n        logger.info(\"Wrote results for source URL: %s\", url)\n\nasync def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n    \"\"\"Crawl & write concurrently to `file` for multiple `urls`.\"\"\"\n    async with ClientSession() as session:\n        tasks = []\n        for url in urls:\n            tasks.append(\n                write_one(file=file, url=url, session=session, **kwargs)\n            )\n        await asyncio.gather(*tasks)\n\nif __name__ == \"__main__\":\n    import pathlib\n    import sys\n\n    assert sys.version_info >= (3, 7), \"Script requires Python 3.7+.\"\n    here = pathlib.Path(__file__).parent\n\n    with open(here.joinpath(\"urls.txt\")) as infile:\n        urls = set(map(str.strip, infile))\n\n    outpath = here.joinpath(\"foundurls.txt\")\n    with open(outpath, \"w\") as outfile:\n        outfile.write(\"source_url\\tparsed_url\\n\")\n\n    asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))"], "metadata": {}}, {"cell_type": "markdown", "source": ["This script is longer than our initial toy programs, so let\u2019s break it down."], "metadata": {}}, {"cell_type": "markdown", "source": ["The constant `HREF_RE` is a [regular expression](https://realpython.com/regex-python/) to extract what we\u2019re ultimately searching for, `href` tags within HTML:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> HREF_RE.search('Go to <a href=\"https://realpython.com/\">Real Python</a>')\n<re.Match object; span=(15, 45), match='href=\"https://realpython.com/\"'>"], "metadata": {}}, {"cell_type": "markdown", "source": ["The coroutine `fetch_html()` is a wrapper around a GET request to make the request and decode the resulting page HTML. It makes the request, awaits the response, and raises right away in the case of a non-200 status:"], "metadata": {}}, {"cell_type": "code", "source": ["resp = await session.request(method=\"GET\", url=url, **kwargs)\nresp.raise_for_status()"], "metadata": {}}, {"cell_type": "markdown", "source": ["If the status is okay, `fetch_html()` returns the page HTML (a `str`). Notably, there is no exception handling done in this function. The logic is to propagate that exception to the caller and let it be handled there:"], "metadata": {}}, {"cell_type": "code", "source": ["html = await resp.text()"], "metadata": {}}, {"cell_type": "markdown", "source": ["We `await` `session.request()` and `resp.text()` because they\u2019re awaitable coroutines. The request/response cycle would otherwise be the long-tailed, time-hogging portion of the application, but with async IO, `fetch_html()` lets the event loop work on other readily available jobs such as parsing and writing URLs that have already been fetched."], "metadata": {}}, {"cell_type": "markdown", "source": ["Next in the chain of coroutines comes `parse()`, which waits on `fetch_html()` for a given URL, and then extracts all of the `href` tags from that page\u2019s HTML, making sure that each is valid and formatting it as an absolute path."], "metadata": {}}, {"cell_type": "markdown", "source": ["Admittedly, the second portion of `parse()` is blocking, but it consists of a quick regex match and ensuring that the links discovered are made into absolute paths."], "metadata": {}}, {"cell_type": "markdown", "source": ["In this specific case, this synchronous code should be quick and inconspicuous. But just remember that any line within a given coroutine will block other coroutines unless that line uses `yield`, `await`, or `return`. If the parsing was a more intensive process, you might want to consider running this portion in its own process with [`loop.run_in_executor()`](https://docs.python.org/3/library/asyncio-eventloop.html#executing-code-in-thread-or-process-pools)."], "metadata": {}}, {"cell_type": "markdown", "source": ["Next, the coroutine `write()` takes a file object and a single URL, and waits on `parse()` to return a `set` of the parsed URLs, writing each to the file asynchronously along with its source URL through use of `aiofiles`, a package for async file IO."], "metadata": {}}, {"cell_type": "markdown", "source": ["Lastly, `bulk_crawl_and_write()` serves as the main entry point into the script\u2019s chain of coroutines. It uses a single session, and a task is created for each URL that is ultimately read from `urls.txt`."], "metadata": {}}, {"cell_type": "markdown", "source": ["Here are a few additional points that deserve mention:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nThe default `ClientSession` has an [adapter](https://aiohttp.readthedocs.io/en/stable/client_reference.html#connectors) with a maximum of 100 open connections. To change that, pass an instance of `asyncio.connector.TCPConnector` to `ClientSession`. You can also specify limits on a per-host basis.\n\n\n\n- \nYou can specify max [timeouts](https://aiohttp.readthedocs.io/en/stable/client_quickstart.html#timeouts) for both the session as a whole and for individual requests.\n\n\n\n- \nThis script also uses `async with`, which works with an [asynchronous context manager](https://www.python.org/dev/peps/pep-0492/#asynchronous-context-managers-and-async-with). I haven\u2019t devoted a whole section to this concept because the transition from synchronous to asynchronous context managers is fairly straightforward. The latter has to define `.__aenter__()` and `.__aexit__()` rather than `.__exit__()` and `.__enter__()`. As you might expect, `async with` can only be used inside a coroutine function declared with `async def`.\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["If you\u2019d like to explore a bit more, the [companion files](https://github.com/realpython/materials/tree/master/asyncio-walkthrough) for this tutorial up at GitHub have comments and docstrings attached as well."], "metadata": {}}, {"cell_type": "markdown", "source": ["Here\u2019s the execution in all of its glory, as `areq.py` gets, parses, and saves results for 9 URLs in under a second:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ python3 areq.py\n21:33:22 DEBUG:asyncio: Using selector: KqueueSelector\n21:33:22 INFO:areq: Got response [200] for URL: https://www.mediamatters.org/\n21:33:22 INFO:areq: Found 115 links for https://www.mediamatters.org/\n21:33:22 INFO:areq: Got response [200] for URL: https://www.nytimes.com/guides/\n21:33:22 INFO:areq: Got response [200] for URL: https://www.politico.com/tipsheets/morning-money\n21:33:22 INFO:areq: Got response [200] for URL: https://www.ietf.org/rfc/rfc2616.txt\n21:33:22 ERROR:areq: aiohttp exception for https://docs.python.org/3/this-url-will-404.html [404]: Not Found\n21:33:22 INFO:areq: Found 120 links for https://www.nytimes.com/guides/\n21:33:22 INFO:areq: Found 143 links for https://www.politico.com/tipsheets/morning-money\n21:33:22 INFO:areq: Wrote results for source URL: https://www.mediamatters.org/\n21:33:22 INFO:areq: Found 0 links for https://www.ietf.org/rfc/rfc2616.txt\n21:33:22 INFO:areq: Got response [200] for URL: https://1.1.1.1/\n21:33:22 INFO:areq: Wrote results for source URL: https://www.nytimes.com/guides/\n21:33:22 INFO:areq: Wrote results for source URL: https://www.politico.com/tipsheets/morning-money\n21:33:22 INFO:areq: Got response [200] for URL: https://www.bloomberg.com/markets/economics\n21:33:22 INFO:areq: Found 3 links for https://www.bloomberg.com/markets/economics\n21:33:22 INFO:areq: Wrote results for source URL: https://www.bloomberg.com/markets/economics\n21:33:23 INFO:areq: Found 36 links for https://1.1.1.1/\n21:33:23 INFO:areq: Got response [200] for URL: https://regex101.com/\n21:33:23 INFO:areq: Found 23 links for https://regex101.com/\n21:33:23 INFO:areq: Wrote results for source URL: https://regex101.com/\n21:33:23 INFO:areq: Wrote results for source URL: https://1.1.1.1/\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["That\u2019s not too shabby! As a sanity check, you can check the line-count on the output. In my case, it\u2019s 626, though keep in mind this may fluctuate:"], "metadata": {}}, {"cell_type": "markdown", "source": ["```sh\n$ wc -l foundurls.txt\n     626 foundurls.txt\n\n$ head -n 3 foundurls.txt\nsource_url  parsed_url\nhttps://www.bloomberg.com/markets/economics https://www.bloomberg.com/feedback\nhttps://www.bloomberg.com/markets/economics https://www.bloomberg.com/notices/tos\n```"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io_in_context\"></a>\n", "\n", "## Async IO in Context"], "metadata": {}}, {"cell_type": "markdown", "source": ["Now that you\u2019ve seen a healthy dose of code, let\u2019s step back for a minute and consider when async IO is an ideal option and how you can make the comparison to arrive at that conclusion or otherwise choose a different model of concurrency."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"when_and_why_is_async_io_the_right_choice?\"></a>\n", "\n", "### When and Why Is Async IO the Right Choice?"], "metadata": {}}, {"cell_type": "markdown", "source": ["This tutorial is no place for an extended treatise on async IO versus threading versus multiprocessing. However, it\u2019s useful to have an idea of when async IO is probably the best candidate of the three."], "metadata": {}}, {"cell_type": "markdown", "source": ["The battle over async IO versus multiprocessing is not really a battle at all. In fact, they can be [used in concert](https://youtu.be/0kXaLh8Fz3k?t=10m30s). If you have multiple, fairly uniform CPU-bound tasks (a great example is a [grid search](http://scikit-learn.org/stable/modules/grid_search.html#parallelism) in libraries such as `scikit-learn` or `keras`), multiprocessing should be an obvious choice."], "metadata": {}}, {"cell_type": "markdown", "source": ["Simply putting `async` before every function is a bad idea if all of the functions use blocking calls. (This can actually slow down your code.) But as mentioned previously, there are places where async IO and multiprocessing can [live in harmony](https://youtu.be/0kXaLh8Fz3k?t=10m30s)."], "metadata": {}}, {"cell_type": "markdown", "source": ["The contest between async IO and threading is a little bit more direct. I mentioned in the introduction that \u201cthreading is hard.\u201d The full story is that, even in cases where threading seems easy to implement, it can still lead to infamous impossible-to-trace bugs due to race conditions and memory usage, among other things."], "metadata": {}}, {"cell_type": "markdown", "source": ["Threading also tends to scale less elegantly than async IO, because threads are a system resource with a finite availability. Creating thousands of threads will fail on many machines, and I don\u2019t recommend trying it in the first place. Creating thousands of async IO tasks is completely feasible."], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO shines when you have multiple IO-bound tasks where the tasks would otherwise be dominated by blocking IO-bound wait time, such as:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nNetwork IO, whether your program is the server or the client side\n\n\n\n- \nServerless designs, such as a peer-to-peer, multi-user network like a group chatroom\n\n\n\n- \nRead/write operations where you want to mimic a \u201cfire-and-forget\u201d style but worry less about holding a lock on whatever you\u2019re reading and writing to\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["The biggest reason not to use it is that `await` only supports a specific set of objects that define a specific set of methods. If you want to do async read operations with a certain DBMS, you\u2019ll need to find not just a Python wrapper for that DBMS, but one that supports the `async`/`await` syntax. Coroutines that contain synchronous calls block other coroutines and tasks from running."], "metadata": {}}, {"cell_type": "markdown", "source": ["For a shortlist of libraries that work with `async`/`await`, see the [list](#libraries-that-work-with-asyncawait) at the end of this tutorial."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"async_io_it_is,_but_which_one?\"></a>\n", "\n", "### Async IO It Is, but Which One?"], "metadata": {}}, {"cell_type": "markdown", "source": ["This tutorial focuses on async IO, the `async`/`await` syntax, and using `asyncio` for event-loop management and specifying tasks. `asyncio` certainly isn\u2019t the only async IO library out there. This observation from Nathaniel J. Smith says a lot:"], "metadata": {}}, {"cell_type": "markdown", "source": ["To that end, a few big-name alternatives that do what `asyncio` does, albeit with different APIs and different approaches, are [`curio`](https://github.com/dabeaz/curio) and [`trio`](https://github.com/python-trio/trio). Personally, I think that if you\u2019re building a moderately sized, straightforward program, just using `asyncio` is plenty sufficient and understandable, and lets you avoid adding yet another large dependency outside of Python\u2019s standard library."], "metadata": {}}, {"cell_type": "markdown", "source": ["But by all means, check out `curio` and `trio`, and you might find that they get the same thing done in a way that\u2019s more intuitive for you as the user. Many of the package-agnostic concepts presented here should permeate to alternative async IO packages as well."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"odds_and_ends\"></a>\n", "\n", "## Odds and Ends"], "metadata": {}}, {"cell_type": "markdown", "source": ["In these next few sections, you\u2019ll cover some miscellaneous parts of `asyncio` and `async`/`await` that haven\u2019t fit neatly into the tutorial thus far, but are still important for building and understanding a full program."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"other_top-level_`asyncio`_functions\"></a>\n", "\n", "### Other Top-Level `asyncio` Functions"], "metadata": {}}, {"cell_type": "markdown", "source": ["In addition to `asyncio.run()`, you\u2019ve seen a few other package-level functions such as `asyncio.create_task()` and `asyncio.gather()`."], "metadata": {}}, {"cell_type": "markdown", "source": ["You can use `create_task()` to schedule the execution of a coroutine object, followed by `asyncio.run()`:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> import asyncio\n\n>>> async def coro(seq) -> list:\n...     \"\"\"'IO' wait time is proportional to the max element.\"\"\"\n...     await asyncio.sleep(max(seq))\n...     return list(reversed(seq))\n...\n>>> async def main():\n...     # This is a bit redundant in the case of one task\n...     # We could use `await coro([3, 2, 1])` on its own\n...     t = asyncio.create_task(coro([3, 2, 1]))  # Python 3.7+\n...     await t\n...     print(f't: type {type(t)}')\n...     print(f't done: {t.done()}')\n...\n>>> t = asyncio.run(main())\nt: type <class '_asyncio.Task'>\nt done: True"], "metadata": {}}, {"cell_type": "markdown", "source": ["There\u2019s a subtlety to this pattern: if you don\u2019t `await t` within `main()`, it may finish before `main()` itself signals that it is complete. Because `asyncio.run(main())` [calls `loop.run_until_complete(main())`](https://github.com/python/cpython/blob/7e18deef652a9d413d5dbd19d61073ba7eb5460e/Lib/asyncio/runners.py#L43), the event loop is only concerned (without `await t` present) that `main()` is done, not that the tasks that get created within `main()` are done. Without `await t`, the loop\u2019s other tasks [will be cancelled](https://github.com/python/cpython/blob/7e18deef652a9d413d5dbd19d61073ba7eb5460e/Lib/asyncio/runners.py#L46), possibly before they are completed. If you need to get a list of currently pending tasks, you can use `asyncio.Task.all_tasks()`."], "metadata": {}}, {"cell_type": "markdown", "source": ["Separately, there\u2019s `asyncio.gather()`. While it doesn\u2019t do anything tremendously special, `gather()` is meant to neatly put a collection of coroutines (futures) into a single future. As a result, it returns a single future object, and, if you `await asyncio.gather()` and specify multiple tasks or coroutines, you\u2019re waiting for all of them to be completed. (This somewhat parallels `queue.join()` from our earlier example.) The result of `gather()` will be a list of the results across the inputs:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> import time\n>>> async def main():\n...     t = asyncio.create_task(coro([3, 2, 1]))\n...     t2 = asyncio.create_task(coro([10, 5, 0]))  # Python 3.7+\n...     print('Start:', time.strftime('%X'))\n...     a = await asyncio.gather(t, t2)\n...     print('End:', time.strftime('%X'))  # Should be 10 seconds\n...     print(f'Both tasks done: {all((t.done(), t2.done()))}')\n...     return a\n...\n>>> a = asyncio.run(main())\nStart: 16:20:11\nEnd: 16:20:21\nBoth tasks done: True\n>>> a\n[[1, 2, 3], [0, 5, 10]]"], "metadata": {}}, {"cell_type": "markdown", "source": ["You probably noticed that `gather()` waits on the entire result set of the Futures or coroutines that you pass it. Alternatively, you can loop over `asyncio.as_completed()` to get tasks as they are completed, in the order of completion. The function returns an iterator that yields tasks as they finish. Below, the result of `coro([3, 2, 1])` will be available before `coro([10, 5, 0])` is complete, which is not the case with `gather()`:"], "metadata": {}}, {"cell_type": "code", "source": [">>>>>> async def main():\n...     t = asyncio.create_task(coro([3, 2, 1]))\n...     t2 = asyncio.create_task(coro([10, 5, 0]))\n...     print('Start:', time.strftime('%X'))\n...     for res in asyncio.as_completed((t, t2)):\n...         compl = await res\n...         print(f'res: {compl} completed at {time.strftime(\"%X\")}')\n...     print('End:', time.strftime('%X'))\n...     print(f'Both tasks done: {all((t.done(), t2.done()))}')\n...\n>>> a = asyncio.run(main())\nStart: 09:49:07\nres: [1, 2, 3] completed at 09:49:10\nres: [0, 5, 10] completed at 09:49:17\nEnd: 09:49:17\nBoth tasks done: True"], "metadata": {}}, {"cell_type": "markdown", "source": ["Lastly, you may also see `asyncio.ensure_future()`. You should rarely need it, because it\u2019s a lower-level plumbing API and largely replaced by `create_task()`, which was introduced later."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"the_precedence_of_`await`\"></a>\n", "\n", "### The Precedence of `await`"], "metadata": {}}, {"cell_type": "markdown", "source": ["While they behave somewhat similarly, the `await` keyword has significantly higher precedence than `yield`. This means that, because it is more tightly bound, there are a number of instances where you\u2019d need parentheses in a `yield from` statement that are not required in an analogous `await` statement. For more information, see [examples of `await` expressions](https://www.python.org/dev/peps/pep-0492/#examples-of-await-expressions) from PEP 492."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"conclusion\"></a>\n", "\n", "## Conclusion"], "metadata": {}}, {"cell_type": "markdown", "source": ["You\u2019re now equipped to use `async`/`await` and the libraries built off of it. Here\u2019s a recap of what you\u2019ve covered:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \nAsynchronous IO as a language-agnostic model and a way to effect concurrency by letting coroutines indirectly communicate with each other\n\n\n\n- \nThe specifics of Python\u2019s new `async` and `await` keywords, used to mark and define coroutines\n\n\n\n- \n`asyncio`, the Python package that provides the API to run and manage coroutines\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"resources\"></a>\n", "\n", "## Resources"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"python_version_specifics\"></a>\n", "\n", "### Python Version Specifics"], "metadata": {}}, {"cell_type": "markdown", "source": ["Async IO in Python has evolved swiftly, and it can be hard to keep track of what came when. Here\u2019s a list of Python minor-version changes and introductions related to `asyncio`:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- \n3.3: The `yield from` expression allows for generator delegation.\n\n\n\n- \n3.4: `asyncio` was introduced in the Python standard library with provisional API status.\n\n\n\n- \n3.5: `async` and `await` became a part of the Python grammar, used to signify and wait on coroutines. They were not yet reserved keywords. (You could still define functions or variables named `async` and `await`.)\n\n\n\n- \n3.6: Asynchronous generators and asynchronous comprehensions were introduced. The API of `asyncio` was declared stable rather than provisional.\n\n\n\n- \n3.7: `async` and `await` became reserved keywords. (They cannot be used as identifiers.) They are intended to replace the `asyncio.coroutine()` decorator. `asyncio.run()` was introduced to the `asyncio` package, among [a bunch of other features](https://docs.python.org/3/whatsnew/3.7.html#whatsnew37-asyncio).\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["If you want to be safe (and be able to use `asyncio.run()`), go with Python 3.7 or above to get the full set of features."], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"articles\"></a>\n", "\n", "### Articles"], "metadata": {}}, {"cell_type": "markdown", "source": ["Here\u2019s a curated list of additional resources:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- Real Python: [Speed up your Python Program with Concurrency](https://realpython.com/python-concurrency/)\n- Real Python: [What is the Python Global Interpreter Lock?](https://realpython.com/python-gil/)\n- CPython: The `asyncio` package [source](https://github.com/python/cpython/tree/master/Lib/asyncio)\n- Python docs: [Data model > Coroutines](https://docs.python.org/3/reference/datamodel.html#coroutines)\n- TalkPython: [Async Techniques and Examples in Python](https://training.talkpython.fm/courses/details/async-in-python-with-threading-and-multiprocessing) \n- Brett Cannon: [How the Heck Does Async-Await Work in Python 3.5?](https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/)\n- PYMOTW: [`asyncio`](https://pymotw.com/3/asyncio/)\n- A. Jesse Jiryu Davis and Guido van Rossum: [A Web Crawler With asyncio Coroutines](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html)\n- Andy Pearce: [The State of Python Coroutines: `yield from`](http://www.andy-pearce.com/blog/posts/2016/Jun/the-state-of-python-coroutines-yield-from/)\n- Nathaniel J. Smith: [Some Thoughts on Asynchronous API Design in a Post-`async`/`await` World](https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/)\n- Armin Ronacher: [I don\u2019t understand Python\u2019s Asyncio](http://lucumr.pocoo.org/2016/10/30/i-dont-understand-asyncio/)\n- Andy Balaam: [series on `asyncio`](http://www.artificialworlds.net/blog/2017/05/31/basic-ideas-of-python-3-asyncio-concurrency/) (4 posts)\n- Stack Overflow: [Python `asyncio.semaphore` in `async`-`await` function](https://stackoverflow.com/q/40836800/7954504)\n- Yeray Diaz:* [AsyncIO for the Working Python Developer](https://hackernoon.com/asyncio-for-the-working-python-developer-5c468e6e2e8e)\n* [Asyncio Coroutine Patterns: Beyond `await`](https://medium.com/python-pandemonium/asyncio-coroutine-patterns-beyond-await-a6121486656f)\n\n\n\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["A few Python *What\u2019s New* sections explain the motivation behind language changes in more detail:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [What\u2019s New in Python 3.3](https://docs.python.org/3/whatsnew/3.3.html#pep-380) (`yield from` and PEP 380)\n- [What\u2019s New in Python 3.6](https://docs.python.org/3/whatsnew/3.6.html#whatsnew36-pep525) (PEP 525 & 530)\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["From David Beazley:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [Generator: Tricks for Systems Programmers](http://www.dabeaz.com/generators/)\n- [A Curious Course on Coroutines and Concurrency](http://www.dabeaz.com/coroutines/)\n- [Generators: The Final Frontier](http://dabeaz.com/finalgenerator/index.html)\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["YouTube talks:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018](https://youtu.be/0kXaLh8Fz3k)\n- [Keynote David Beazley - Topics of Interest (Python Asyncio)](https://youtu.be/ZzfHjytDceU)\n- [David Beazley - Python Concurrency From the Ground Up: LIVE! - PyCon 2015](https://youtu.be/MCs5OvhV9S4)\n- [Raymond Hettinger, Keynote on Concurrency, PyBay 2017](https://youtu.be/9zinZmE3Ogk)\n- [Thinking about Concurrency, Raymond Hettinger, Python core developer](https://youtu.be/Bv25Dwe84g0)\n- [Miguel Grinberg Asynchronous Python for the Complete Beginner PyCon 2017](https://youtu.be/iG6fr81xHKA)\n- [Yury Selivanov asyncawait and asyncio in Python 3 6 and beyond PyCon 2017](https://youtu.be/2ZFFv-wZ8_g)\n- [Fear and Awaiting in Async: A Savage Journey to the Heart of the Coroutine Dream](https://youtu.be/E-1Y4kSsAFc)\n- [What Is Async, How Does It Work, and When Should I Use It? (PyCon APAC 2014)](https://youtu.be/kdzL3r-yJZY)\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"related_peps\"></a>\n", "\n", "### Related PEPs"], "metadata": {}}, {"cell_type": "markdown", "source": ["|PEP|Date Created|\n|:--|:--|\n|[PEP 342 \u2013 Coroutines via Enhanced Generators](https://www.python.org/dev/peps/pep-0342/)|2005-05|\n|[PEP 380 \u2013 Syntax for Delegating to a Subgenerator](https://www.python.org/dev/peps/pep-0380/)|2009-02|\n|[PEP 3153 \u2013 Asynchronous IO support](https://www.python.org/dev/peps/pep-3153/)|2011-05|\n|[PEP 3156 \u2013 Asynchronous IO Support Rebooted: the \u201casyncio\u201d Module](https://www.python.org/dev/peps/pep-3156/)|2012-12|\n|[PEP 492 \u2013 Coroutines with async and await syntax](https://www.python.org/dev/peps/pep-0492/)|2015-04|\n|[PEP 525 \u2013 Asynchronous Generators](https://www.python.org/dev/peps/pep-0525/)|2016-07|\n|[PEP 530 \u2013 Asynchronous Comprehensions](https://www.python.org/dev/peps/pep-0530/)|2016-09|\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["<a class=\"anchor\" id=\"libraries_that_work_with_`async`/`await`\"></a>\n", "\n", "### Libraries That Work With `async`/`await`"], "metadata": {}}, {"cell_type": "markdown", "source": ["From [aio-libs](https://github.com/aio-libs):"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [`aiohttp`](https://github.com/aio-libs/aiohttp): Asynchronous HTTP client/server framework\n- [`aioredis`](https://github.com/aio-libs/aioredis): Async IO Redis support\n- [`aiopg`](https://github.com/aio-libs/aiopg): Async IO PostgreSQL support\n- [`aiomcache`](https://github.com/aio-libs/aiomcache): Async IO memcached client\n- [`aiokafka`](https://github.com/aio-libs/aiokafka): Async IO Kafka client\n- [`aiozmq`](https://github.com/aio-libs/aiozmq): Async IO ZeroMQ support\n- [`aiojobs`](https://github.com/aio-libs/aiojobs): Jobs scheduler for managing background tasks\n- [`async_lru`](https://github.com/aio-libs/async_lru): Simple [LRU cache](https://realpython.com/lru-cache-python/) for async IO\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["From [magicstack](https://magic.io/):"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [`uvloop`](https://github.com/MagicStack/uvloop): Ultra fast async IO event loop\n- [`asyncpg`](https://github.com/MagicStack/asyncpg): (Also very fast) async IO PostgreSQL support\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["From other hosts:"], "metadata": {}}, {"cell_type": "markdown", "source": ["- [`trio`](https://github.com/python-trio/trio): Friendlier `asyncio` intended to showcase a radically simpler design\n- [`aiofiles`](https://github.com/Tinche/aiofiles): Async file IO\n- [`asks`](https://github.com/theelous3/asks): Async requests-like http library\n- [`asyncio-redis`](https://github.com/jonathanslenders/asyncio-redis): Async IO Redis support\n- [`aioprocessing`](https://github.com/dano/aioprocessing): Integrates `multiprocessing` module with `asyncio`\n- [`umongo`](https://github.com/Scille/umongo): Async IO MongoDB client\n- [`unsync`](https://github.com/alex-sherman/unsync): Unsynchronize `asyncio`\n- [`aiostream`](https://github.com/vxgmichel/aiostream): Like `itertools`, but async\n"], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}}, "nbformat": 4, "nbformat_minor": 5}